{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cea47c22-5444-4376-ac6c-0b18f51e536f",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5212f831-ffc5-44fc-81a7-0560395e466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5547097b-8732-478e-8d53-8db2dd900563",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"gene_expression/gene_expression_files\"  \n",
    "mapping_file = \"gdc_mapping.tsv\"  \n",
    "\n",
    "#filter for .tsv-- these will be the gene expression files only\n",
    "mapping = pd.read_csv(mapping_file, sep=\"\\t\")\n",
    "mapping = mapping[mapping[\"Sample Type\"] == \"Primary Tumor\"] #important-- this step was missed. first i just filtered for \"tumor\" and it gave other things in the cohort.\n",
    "tsv_files = mapping[mapping[\"File Name\"].str.endswith(\".tsv\")]\n",
    "expression_data = {}\n",
    "\n",
    "for _, row in tsv_files.iterrows():\n",
    "    file_name = row[\"File Name\"]  # Exact filename with extension-- the extension is included in the file name\n",
    "    sample_id = row[\"Sample ID\"]\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            # Read the first 5 rows to confirm column format, skipping the first row (header=1). Was getting weird skipping at first. \n",
    "            exp_levels = pd.read_csv(file_path, sep=\"\\t\", header=1, nrows=5)\n",
    "            required_cols = {\"gene_name\", \"gene_type\", \"tpm_unstranded\"}\n",
    "            if not required_cols.issubset(exp_levels.columns):\n",
    "                print(f\"Skipping {file_name}: Missing expected columns.\")\n",
    "                continue\n",
    "            exp_levels = pd.read_csv(file_path, sep=\"\\t\", header=1, usecols=required_cols)\n",
    "            exp_levels = exp_levels[exp_levels[\"gene_type\"] == \"protein_coding\"]\n",
    "            exp_levels = exp_levels[[\"gene_name\", \"tpm_unstranded\"]].set_index(\"gene_name\")\n",
    "            expression_data[sample_id] = exp_levels[\"tpm_unstranded\"]\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_name}: {e}\")\n",
    "    else:\n",
    "        print(f\"Warning: File {file_name} not found in {data_dir}\")\n",
    "\n",
    "expression_matrix = pd.DataFrame(expression_data)\n",
    "expression_matrix = expression_matrix.sort_index().astype(float)\n",
    "\n",
    "output_file = \"gene_expression_matrix.tsv\"\n",
    "expression_matrix.to_csv(output_file, sep=\"\\t\")\n",
    "\n",
    "print(f\"Gene expression matrix saved as {output_file}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaae0c99-61d6-449a-8797-1c07106763ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = dict(zip(mapping_df['File Name'], mapping_df['Sample ID']))\n",
    "\n",
    "def extract_mutations(filepath):\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, low_memory=False)\n",
    "        non_silent = df[~df['Variant_Classification'].isin([\n",
    "            'Silent', 'Intron', 'IGR', '3\\'UTR', '5\\'UTR', '3\\'Flank', '5\\'Flank', 'RNA', 'lincRNA'])]\n",
    "        return non_silent[['Tumor_Sample_Barcode', 'Hugo_Symbol']].dropna()\n",
    "    except:\n",
    "        return pd.DataFrame(columns=['Tumor_Sample_Barcode', 'Hugo_Symbol'])\n",
    "\n",
    "all_mutations = []\n",
    "\n",
    "for filepath in glob(os.path.join(\"extracted/somatic_mutations\", \"*.maf.csv\")):\n",
    "    # Get the file name base (no directory, no extension)\n",
    "    base_name = os.path.basename(filepath).replace(\".maf.csv\", \"\")\n",
    "    mapped_filename = f\"{base_name}.maf.gz\"\n",
    "\n",
    "    sample_id = mapping_dict.get(mapped_filename)\n",
    "    if not sample_id:\n",
    "        print(f\"Warning: {mapped_filename} not found in mapping file.\")\n",
    "        continue\n",
    "\n",
    "    df = extract_mutations(filepath)\n",
    "    if not df.empty:\n",
    "        df['Sample_ID'] = sample_id\n",
    "        all_mutations.append(df[['Sample_ID', 'Hugo_Symbol']])\n",
    "combined = pd.concat(all_mutations).drop_duplicates()\n",
    "combined['value'] = 1\n",
    "binary_matrix = combined.pivot_table(index='Hugo_Symbol', columns='Sample_ID', values='value', fill_value=0)\n",
    "binary_matrix.to_csv(\"somatic_mutation_matrix_by_sample_id.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf38c85b-d76b-4459-a83c-0421f7995d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"gene expression\")\n",
    "expression_df = pd.read_csv(\"gene_expression_matrix.tsv\", index_col=0, sep=\"\\t\")\n",
    "print(f\"Expression matrix shape: {expression_df.shape}\")\n",
    "print(f\"Expression matrix columns (samples): {expression_df.columns[:5]}\")  \n",
    "print(f\"Expression matrix index (genes) sample: {expression_df.index[:5]}\")  \n",
    "\n",
    "print(\"\\nsomatic mutation matrix\")\n",
    "mutation_df = pd.read_csv(\"somatic_mutation_matrix_by_sample_id.csv\", index_col=0)\n",
    "print(f\"Mutation matrix shape: {mutation_df.shape}\")\n",
    "print(f\"Mutation matrix columns (samples): {mutation_df.columns[:5]}\")\n",
    "print(f\"Mutation matrix index (genes) sample: {mutation_df.index[:5]}\")\n",
    "\n",
    "mutation_df.columns = mutation_df.columns.str.strip()\n",
    "\n",
    "expression_df = expression_df[~expression_df.index.duplicated(keep='first')]\n",
    "mutation_df = mutation_df[~mutation_df.index.duplicated(keep='first')]\n",
    "print(\"\\nDropped duplicate genes if any.\")\n",
    "\n",
    "expression_df.index.name = \"gene_name\"\n",
    "mutation_df.index.name = \"gene_name\"\n",
    "\n",
    "print(\"\\nBefore stripping last 3 chars from sample IDs:\")\n",
    "print(f\"Expression columns example: {list(expression_df.columns[:5])}\")\n",
    "print(f\"Mutation columns example: {list(mutation_df.columns[:5])}\")\n",
    "\n",
    "expression_df.columns = [col[:-3] if len(col) > 3 else col for col in expression_df.columns]\n",
    "mutation_df.columns = [col[:-3] if len(col) > 3 else col for col in mutation_df.columns]\n",
    "dup_expr = expression_df.columns.duplicated()\n",
    "dup_mut = mutation_df.columns.duplicated()\n",
    "\n",
    "print(f\"\\nDuplicate sample IDs in expression: {expression_df.columns[dup_expr].tolist()}\")\n",
    "print(f\"Duplicate sample IDs in mutation: {mutation_df.columns[dup_mut].tolist()}\")\n",
    "\n",
    "expression_df = expression_df.loc[:, ~dup_expr]\n",
    "mutation_df = mutation_df.loc[:, ~dup_mut]\n",
    "\n",
    "print(\"\\nAfter stripping last 3 chars from sample IDs (Case IDs):\")\n",
    "print(f\"Expression columns example: {list(expression_df.columns[:5])}\")\n",
    "print(f\"Mutation columns example: {list(mutation_df.columns[:5])}\")\n",
    "\n",
    "all_genes = expression_df.index\n",
    "\n",
    "mutation_aligned = mutation_df.reindex(all_genes, fill_value=0)\n",
    "\n",
    "common_samples = expression_df.columns.intersection(mutation_aligned.columns)\n",
    "expression_filtered = expression_df[common_samples]\n",
    "mutation_filtered = mutation_aligned[common_samples]\n",
    "\n",
    "print(f\"Number of genes (expression): {expression_filtered.shape[0]}\")\n",
    "print(f\"Number of samples: {len(common_samples)}\")\n",
    "expression_T = expression_filtered.T\n",
    "mutation_T = mutation_filtered.T\n",
    "\n",
    "print(f\"Transposed expression shape: {expression_T.shape}\")\n",
    "print(f\"Transposed mutation shape: {mutation_T.shape}\")\n",
    "\n",
    "merged_df = pd.concat([expression_T, mutation_T], axis=1)\n",
    "print(f\"Merged matrix shape (samples × features): {merged_df.shape}\")\n",
    "merged_df.to_csv(\"merged_expression_mutation.csv\")\n",
    "print(\"\\nMerged matrix saved as 'merged_expression_mutation.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0477351b-e4ac-4e3c-b056-1d34b501e11a",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6aaa17-c050-48a9-8f98-497c79f8ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Log-transform and scale from 0-1\n",
    "expression_data_log = np.log1p(expression_T)\n",
    "scaler_expr = MinMaxScaler()\n",
    "expression_scaled = scaler_expr.fit_transform(expression_data_log)\n",
    "# Mutation data as-is (0/1)\n",
    "y_flat = mutation_T.values.flatten()\n",
    "n_positives = np.sum(y_flat == 1)\n",
    "n_negatives = np.sum(y_flat == 0)\n",
    "#pos_weight = n_negatives / (n_positives + 1e-6)  # Avoid divide by zero\n",
    "#print(pos_weight)\n",
    "#pos_weight = min(pos_weight, 10)\n",
    "#print(pos_weight)\n",
    "mutation_binary = mutation_T.astype(np.float32)\n",
    "# Flatten binary mutation matrix\n",
    "\n",
    "def build_autoencoder(input_dim, encoding_dim=200):\n",
    "    input_layer = keras.Input(shape=(input_dim,))\n",
    "    encoded = layers.Dense(800, activation='relu')(input_layer)\n",
    "    encoded = layers.Dense(400, activation='relu')(encoded)\n",
    "    encoded = layers.Dense(encoding_dim, activation='relu')(encoded)\n",
    "    \n",
    "    \n",
    "    decoded = layers.Dense(400, activation='relu')(encoded)\n",
    "    decoded = layers.Dense(800, activation='relu')(decoded)\n",
    "    decoded = layers.Dense(input_dim, activation='sigmoid')(decoded)\n",
    "    autoencoder = keras.Model(input_layer, decoded)\n",
    "    encoder = keras.Model(input_layer, encoded)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=1e-4), loss='mse')\n",
    "    return autoencoder, encoder\n",
    "\n",
    "#def weighted_binary_crossentropy(pos_weight):\n",
    "    #def loss(y_true, y_pred):\n",
    "        #epsilon = K.epsilon()\n",
    "        #y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "        #logloss = -(pos_weight * y_true * K.log(y_pred) + (1 - y_true) * K.log(1 - y_pred))\n",
    "        #return K.mean(logloss, axis=-1)\n",
    "    #return loss\n",
    "\n",
    "\n",
    "def build_mutation_autoencoder(input_dim, encoding_dim=200, dropout_rate=0.4):\n",
    "    input_layer = keras.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(800, activation='relu')(input_layer)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(400, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    encoded = layers.Dense(encoding_dim, activation='relu')(x)\n",
    "    \n",
    "    x = layers.Dense(400, activation='relu')(encoded)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(800, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    decoded = layers.Dense(input_dim, activation='sigmoid')(x)\n",
    "\n",
    "    autoencoder = keras.Model(inputs=input_layer, outputs=decoded)\n",
    "    encoder = keras.Model(inputs=input_layer, outputs=encoded)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=5e-5, decay=1e-5), loss=\"binary_crossentropy\")\n",
    "    return autoencoder, encoder\n",
    "\n",
    "\n",
    "#Gene expression\n",
    "autoencoder_expr, encoder_expr = build_autoencoder(expression_scaled.shape[1], encoding_dim=200)\n",
    "autoencoder_expr.fit(expression_scaled, expression_scaled,\n",
    "                     epochs=50,\n",
    "                     batch_size=16,\n",
    "                     validation_split=0.25,\n",
    "                     shuffle=True)\n",
    "\n",
    "#Somatic mutation \n",
    "autoencoder_mut, encoder_mut = build_mutation_autoencoder(mutation_binary.shape[1], encoding_dim=200)\n",
    "autoencoder_mut.fit(mutation_binary, mutation_binary,\n",
    "                    epochs=50,\n",
    "                    batch_size=8,\n",
    "                    validation_split=0.25,\n",
    "                    shuffle=True,)\n",
    "\n",
    "latent_expr = encoder_expr.predict(expression_scaled)\n",
    "latent_mut = encoder_mut.predict(mutation_binary)\n",
    "latent_combined = np.hstack([latent_expr, latent_mut])\n",
    "\n",
    "print(f\"Combined latent features shape: {latent_combined.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fffbb9-4ff3-4bea-a1af-d118c53a5171",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = pd.DataFrame(latent_combined, index=merged_df.index, columns=[f\"latent_{i}\" for i in range(latent_combined.shape[1])])\n",
    "encoded_df.to_csv(\"encoder_output__400_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0034a8d9-3f5c-46c2-a515-b288e334c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "expr_recon = autoencoder_expr.predict(expression_scaled)\n",
    "pearsons = []\n",
    "\n",
    "for i in range(expression_scaled.shape[0]):\n",
    "    r, _ = pearsonr(expression_scaled[i], expr_recon[i])\n",
    "    pearsons.append(r)\n",
    "\n",
    "print(f\"Mean Pearson: {np.mean(pearsons):.2f}\")\n",
    "print(f\"Median Pearson: {np.median(pearsons):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0f36af-55ef-49d0-8c00-3f62a4aa1012",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1c4c69-0147-49c4-996a-703180d0a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.mixture import GaussianMixture\n",
    "MIN_CLUSTER_SIZE = 20\n",
    "BIC_RANGE = range(2, 10)\n",
    "RANDOM_STATE = 42\n",
    "REG_COVAR = 1e-3\n",
    "\n",
    "def bic_optimal_n(X, n_range=BIC_RANGE):\n",
    "    bics = []\n",
    "    for n in n_range:\n",
    "        if len(X) <= n:\n",
    "            break\n",
    "        gmm = GaussianMixture(\n",
    "            n_components=n,\n",
    "            random_state=RANDOM_STATE,\n",
    "            reg_covar=REG_COVAR\n",
    "        )\n",
    "        gmm.fit(X)\n",
    "        bics.append(gmm.bic(X))\n",
    "    if not bics:\n",
    "        return 1\n",
    "    return n_range[np.argmin(bics)]\n",
    "\n",
    "def recursive_gmm(encoded_df, min_size=MIN_CLUSTER_SIZE):\n",
    "    df = encoded_df.copy()\n",
    "\n",
    "    # Level 1\n",
    "    opt1 = bic_optimal_n(df)\n",
    "    print(f\"Optimal clusters (Level 1): {opt1}\")\n",
    "\n",
    "    gmm1 = GaussianMixture(\n",
    "        n_components=opt1,\n",
    "        random_state=RANDOM_STATE,\n",
    "        reg_covar=REG_COVAR\n",
    "    ).fit(df)\n",
    "    df[\"cluster_1\"] = gmm1.predict(df)\n",
    "\n",
    "    # Level 2\n",
    "    cluster_counter = 0\n",
    "    df[\"cluster_2\"] = np.nan\n",
    "\n",
    "    for c1 in sorted(df[\"cluster_1\"].unique()):\n",
    "        subset_idx = df.index[df[\"cluster_1\"] == c1]\n",
    "        subset = df.loc[subset_idx, df.columns.difference([\"cluster_1\",\"cluster_2\"], sort=False)]\n",
    "\n",
    "        if len(subset) < min_size * 2:\n",
    "            df.loc[subset_idx, \"cluster_2\"] = cluster_counter\n",
    "            cluster_counter += 1\n",
    "            continue\n",
    "\n",
    "        opt2 = bic_optimal_n(subset)\n",
    "        gmm2 = GaussianMixture(\n",
    "            n_components=opt2,\n",
    "            random_state=RANDOM_STATE,\n",
    "            reg_covar=REG_COVAR\n",
    "        ).fit(subset)\n",
    "        sub_labels = gmm2.predict(subset)\n",
    "\n",
    "        for sub in np.unique(sub_labels):\n",
    "            child_idx = subset_idx[sub_labels == sub]\n",
    "            if len(child_idx) < min_size:\n",
    "                #merging. \n",
    "                df.loc[child_idx, \"cluster_2\"] = cluster_counter\n",
    "            else:\n",
    "                df.loc[child_idx, \"cluster_2\"] = cluster_counter\n",
    "            cluster_counter += 1\n",
    "\n",
    "    # Fixing lables\n",
    "    df[\"cluster_2\"] = df[\"cluster_2\"].astype(\"Int64\")\n",
    "    valid = df[\"cluster_2\"].dropna().unique()\n",
    "    label_map = {old: i+1 for i, old in enumerate(sorted(valid))}\n",
    "    df[\"cluster_final\"] = df[\"cluster_2\"].map(label_map)\n",
    "    df[\"cluster_label\"] = df[\"cluster_final\"].apply(lambda x: f\"C{x}\" if pd.notna(x) else \"unassigned\")\n",
    "\n",
    "    print(\"\\nCluster distribution:\")\n",
    "    print(df[\"cluster_label\"].value_counts())\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f671159-6e22-4dfc-81b4-ccb2912c2939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_clustering(df, feature_cols, start_label_int):\n",
    "    \"\"\"Split each existing cluster (C1–Cn) into subclusters, returning new df and next starting int.\"\"\"\n",
    "    current_labels = sorted(df[\"cluster_label\"].unique())\n",
    "    new_label_counter = start_label_int\n",
    "    df[\"cluster_next\"] = np.nan\n",
    "\n",
    "    for label in current_labels:\n",
    "        sub_idx = df.index[df[\"cluster_label\"] == label]\n",
    "        subset = df.loc[sub_idx, feature_cols]\n",
    "\n",
    "        if len(subset) < MIN_CLUSTER_SIZE * 2:\n",
    "            df.loc[sub_idx, \"cluster_next\"] = new_label_counter\n",
    "            new_label_counter += 1\n",
    "            continue\n",
    "\n",
    "        opt = bic_optimal_n(subset)\n",
    "        gmm = GaussianMixture(\n",
    "            n_components=opt,\n",
    "            random_state=RANDOM_STATE,\n",
    "            reg_covar=REG_COVAR\n",
    "        ).fit(subset)\n",
    "        sub_labels = gmm.predict(subset)\n",
    "\n",
    "        for sub in np.unique(sub_labels):\n",
    "            child_idx = sub_idx[sub_labels == sub]\n",
    "            if len(child_idx) < MIN_CLUSTER_SIZE:\n",
    "                df.loc[child_idx, \"cluster_next\"] = new_label_counter\n",
    "            else:\n",
    "                df.loc[child_idx, \"cluster_next\"] = new_label_counter\n",
    "            new_label_counter += 1\n",
    "\n",
    "    # labels\n",
    "    df[\"cluster_next\"] = df[\"cluster_next\"].astype(\"Int64\")\n",
    "    valid = df[\"cluster_next\"].dropna().unique()\n",
    "    label_map = {old: i+1 for i, old in enumerate(sorted(valid))}\n",
    "    df[\"cluster_final\"] = df[\"cluster_next\"].map(label_map)\n",
    "    df[\"cluster_label\"] = df[\"cluster_final\"].apply(lambda x: f\"C{x}\" if pd.notna(x) else \"unassigned\")\n",
    "\n",
    "    print(\"\\nCluster distribution after next level:\")\n",
    "    print(df[\"cluster_label\"].value_counts())\n",
    "\n",
    "    return df, new_label_counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6566cc-68f1-41aa-ba34-7b83498b9d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = encoded_df.columns  \n",
    "clustered_df, next_label = extend_clustering(clustered_df, feature_cols, start_label_int=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e0a6732e-8d6a-4fe4-9ec2-a4cb39382934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_clusters(df, feature_cols, target_clusters, start_label_int):\n",
    "    \"\"\"Split only selected clusters; keep all other labels unchanged.\"\"\"\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    next_label = start_label_int\n",
    "    df[\"cluster_next\"] = np.nan\n",
    "\n",
    "    for label in df[\"cluster_label\"].unique():\n",
    "        sub_idx = df.index[df[\"cluster_label\"] == label]\n",
    "        subset = df.loc[sub_idx, feature_cols]\n",
    "\n",
    "        # skip clusters not in target list\n",
    "        if label not in target_clusters:\n",
    "            df.loc[sub_idx, \"cluster_next\"] = next_label\n",
    "            next_label += 1\n",
    "            continue\n",
    "\n",
    "        if len(subset) < MIN_CLUSTER_SIZE * 2:\n",
    "            df.loc[sub_idx, \"cluster_next\"] = next_label\n",
    "            next_label += 1\n",
    "            continue\n",
    "\n",
    "        opt = bic_optimal_n(subset)\n",
    "        gmm = GaussianMixture(\n",
    "            n_components=opt,\n",
    "            random_state=RANDOM_STATE,\n",
    "            reg_covar=REG_COVAR\n",
    "        ).fit(subset)\n",
    "        sub_labels = gmm.predict(subset)\n",
    "\n",
    "        for sub in np.unique(sub_labels):\n",
    "            child_idx = sub_idx[sub_labels == sub]\n",
    "            if len(child_idx) < MIN_CLUSTER_SIZE:\n",
    "                df.loc[child_idx, \"cluster_next\"] = next_label\n",
    "            else:\n",
    "                df.loc[child_idx, \"cluster_next\"] = next_label\n",
    "            next_label += 1\n",
    "\n",
    "    # clean labels\n",
    "    df[\"cluster_next\"] = df[\"cluster_next\"].astype(\"Int64\")\n",
    "    valid = df[\"cluster_next\"].dropna().unique()\n",
    "    label_map = {old: i + 1 for i, old in enumerate(sorted(valid))}\n",
    "    df[\"cluster_final\"] = df[\"cluster_next\"].map(label_map)\n",
    "    df[\"cluster_label\"] = df[\"cluster_final\"].apply(lambda x: f\"C{x}\" if pd.notna(x) else \"unassigned\")\n",
    "\n",
    "    print(\"\\nCluster distribution after refinement:\")\n",
    "    print(df[\"cluster_label\"].value_counts().sort_index())\n",
    "\n",
    "    return df, next_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa958b7-8181-412b-bd6a-193363c9e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = encoded_df.columns \n",
    "target_clusters = [\"C4\", \"C7\"]   \n",
    "clustered_df, next_label = refine_clusters(\n",
    "    clustered_df,\n",
    "    feature_cols,\n",
    "    target_clusters,\n",
    "    start_label_int=8  #currently 7 clusters\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee37d163-b658-45f7-842f-3db8a25148a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_df[\"cluster_label\"].value_counts().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98767c8d-d8ba-4708-ac53-e2e9a7f0097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "reducer = umap.UMAP(random_state=42)\n",
    "embedding = reducer.fit_transform(encoded_df)\n",
    "umap_df = pd.DataFrame(embedding, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "umap_df[\"cluster\"] = clustered_df[\"cluster_label\"].values\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.scatterplot(data=umap_df, x=\"UMAP1\", y=\"UMAP2\", hue=\"cluster\", s=20, palette=\"tab10\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.title(\"UMAP colored by clusters\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad97977-e898-48c8-8ed8-6ee43e2840af",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = encoded_df.columns\n",
    "target_clusters = [\"C3\", \"C7\"]   \n",
    "clustered_df, next_label = refine_clusters(\n",
    "    clustered_df,\n",
    "    feature_cols,\n",
    "    target_clusters,\n",
    "    start_label_int=10    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba09c6d-b6ed-4f5f-b360-38fff91549d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def merge_small_clusters(df, feature_cols, min_size=20):\n",
    "    \"\"\"\n",
    "    I tried merging clusters smaller than min_size into the nearest larger cluster\n",
    "    using distance between centroids in space. \n",
    "    This ended up being pointless becaues they went\n",
    "    to their parent cluster anyways...\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    cluster_sizes = df[\"cluster_label\"].value_counts()\n",
    "    small_clusters = cluster_sizes[cluster_sizes < min_size].index.tolist()\n",
    "    large_clusters = cluster_sizes[cluster_sizes >= min_size].index.tolist()\n",
    "    if not small_clusters:\n",
    "        print(\"No small clusters to merge.\")\n",
    "        return df\n",
    "\n",
    "    print(f\"Merging clusters smaller than {min_size}: {small_clusters}\")\n",
    "    \n",
    "    centroids = (\n",
    "        df.groupby(\"cluster_label\")[feature_cols]\n",
    "        .mean()\n",
    "        .loc[cluster_sizes.index]\n",
    "    )\n",
    "\n",
    "    for small in small_clusters:\n",
    "        dists = pairwise_distances(\n",
    "            centroids.loc[[small]], centroids.loc[large_clusters]\n",
    "        )[0]\n",
    "        nearest_large = large_clusters[np.argmin(dists)]\n",
    "        print(f\"→ {small} merged into {nearest_large}\")\n",
    "        \n",
    "        #Assigning Samples\n",
    "        df.loc[df[\"cluster_label\"] == small, \"cluster_label\"] = nearest_large\n",
    "    df[\"cluster_label\"] = (\n",
    "        df[\"cluster_label\"]\n",
    "        .astype(\"category\")\n",
    "        .cat.rename_categories(\n",
    "            {old: f\"C{i+1}\" for i, old in enumerate(sorted(df['cluster_label'].unique()))}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(\"\\nCluster distribution after merging:\")\n",
    "    print(df[\"cluster_label\"].value_counts().sort_index())\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a78f161-0aad-4a33-b254-7011f7fe377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = encoded_df.columns\n",
    "clustered_df = merge_small_clusters(clustered_df, feature_cols, min_size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92253a8b-a78d-49f4-a628-129f082e11e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_clusters = clustered_df[[\"cluster_label\"]].copy()\n",
    "final_clusters.to_csv(\"final_cluster_assignments.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6c671a-b7df-449e-a943-71d60441c93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [c for c in clustered_df.columns if c.startswith(\"cluster_\")]\n",
    "print(\"Available cluster columns:\", cols)\n",
    "#making sure everything is mapped well\n",
    "mapping_df = clustered_df.groupby([cols[0], \"cluster_label\"]).size().reset_index(name=\"count\")\n",
    "mapping_df = mapping_df.sort_values([cols[0], \"count\"], ascending=[True, False])\n",
    "print(\"\\nParent --> child mapping: \")\n",
    "print(mapping_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3f9bef-8db4-42fd-abe2-8491b2a114b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_child_map = (\n",
    "    mapping_df[mapping_df[\"count\"] > 0]\n",
    "    .groupby(\"cluster_1\")[\"cluster_label\"]\n",
    "    .apply(list)\n",
    "    .reset_index()\n",
    ")\n",
    "parent_child_map.columns = [\"Parent_cluster\", \"Child_clusters\"]\n",
    "print(parent_child_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7751deb-c469-41f9-b0e6-3398e6d046cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify which cluster columns exist\n",
    "cols = [c for c in clustered_df.columns if c.startswith(\"cluster_\")]\n",
    "print(\"Cluster columns:\", cols)\n",
    "\n",
    "for i in range(len(cols) - 1):\n",
    "    print(f\"\\nLevel {i+1} → Level {i+2} mapping:\")\n",
    "    m = (\n",
    "        clustered_df.groupby([cols[i], cols[i+1]])\n",
    "        .size()\n",
    "        .reset_index(name=\"count\")\n",
    "        .query(\"count > 0\")\n",
    "        .sort_values([cols[i], \"count\"], ascending=[True, False])\n",
    "    )\n",
    "    print(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c316efa-837d-480f-aab2-48bff76ac6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Supervised UMAP to visualize the clusters. \n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(clustered_df[\"cluster_label\"])\n",
    "\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    metric=\"cosine\",\n",
    "    random_state=42,\n",
    "    target_metric=\"categorical\",\n",
    "    target_weight=0.5  \n",
    ")\n",
    "embedding = reducer.fit_transform(encoded_df, y=y)\n",
    "umap_df = pd.DataFrame(embedding, columns=[\"UMAP1\", \"UMAP2\"])\n",
    "umap_df[\"Cluster\"] = clustered_df[\"cluster_label\"].values\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "sns.scatterplot(\n",
    "    data=umap_df,\n",
    "    x=\"UMAP1\", y=\"UMAP2\",\n",
    "    hue=\"Cluster\",\n",
    "    s=28, alpha=0.9, linewidth=0, palette=\"tab10\"\n",
    ")\n",
    "plt.title(\"Supervised UMAP (guided by cluster labels)\", fontsize=13)\n",
    "plt.xlabel(\"UMAP1\"); plt.ylabel(\"UMAP2\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14812aa-f636-4b78-83f3-f6f92262fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim the limits, this umap has so much space.\n",
    "x_low, x_high = np.percentile(umap_df[\"UMAP1\"], [1, 99])\n",
    "y_low, y_high = np.percentile(umap_df[\"UMAP2\"], [1, 99])\n",
    "fig, ax = plt.subplots(figsize=(9,8), dpi=300)\n",
    "sns.scatterplot(\n",
    "    data=umap_df,\n",
    "    x=\"UMAP1\", y=\"UMAP2\",\n",
    "    hue=\"Cluster\",\n",
    "    palette=palette,\n",
    "    s=8, alpha=0.85, linewidth=0,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_xlim(x_low, x_high)\n",
    "ax.set_ylim(y_low, y_high)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "ax.set_title(\"UMAP projection of latent features (C1–C9)\", fontsize=14)\n",
    "ax.set_xlabel(\"UMAP1\", fontsize=12)\n",
    "ax.set_ylabel(\"UMAP2\", fontsize=12)\n",
    "ax.legend(\n",
    "    title=\"Cluster\",\n",
    "    bbox_to_anchor=(1.12, 1),\n",
    "    loc=\"upper left\",\n",
    "    borderaxespad=0.,\n",
    "    markerscale=1.5\n",
    ")\n",
    "fig.tight_layout(pad=0)\n",
    "plt.subplots_adjust(right=0.85)\n",
    "fig.savefig(\"final_figures/UMAP/UMAP_clusters_zoom.png\", dpi=600, bbox_inches=\"tight\")\n",
    "fig.savefig(\"final_figures/UMAP/UMAP_clusters_zoom.pdf\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8c96e3-edba-4e31-8b50-d7226dcc86c6",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934277c8-81ff-4e19-b469-63b10e7f2086",
   "metadata": {},
   "source": [
    "### Hallmark Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced58be2-b7bc-48a0-96bb-2c30089e1f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gseapy as gp \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2f9936-682a-4a19-8560-36d92dc67b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.get_library_name(organism='Human')[:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d20ab-7508-49b2-b80c-6426b18168d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hallmark_sets = gp.get_library(name=\"MSigDB_Hallmark_2020\", organism=\"Human\")\n",
    "print(f\"Loaded {len(hallmark_sets)} Hallmark pathways\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238accc8-0751-41ed-97ec-87092c4ba455",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = np.log2(expression_T + 1)\n",
    "meta = clustered_df.copy()\n",
    "os.makedirs(\"DE_lists\", exist_ok=True)\n",
    "\n",
    "# align samples between expression and clusters\n",
    "common_samples = expr.index.intersection(meta.index)\n",
    "expr = expr.loc[common_samples].copy()\n",
    "meta = meta.loc[common_samples].copy()\n",
    "print(f\"{len(common_samples)} samples aligned between expr and clusters.\")\n",
    "\n",
    "# differential expression for each cluster vs all others\n",
    "de_results = {}\n",
    "\n",
    "for cl in sorted(meta[\"cluster_label\"].unique()):\n",
    "    in_group = meta[\"cluster_label\"] == cl\n",
    "    out_group = ~in_group\n",
    "    means_in = expr.loc[in_group].mean(axis=0)\n",
    "    means_out = expr.loc[out_group].mean(axis=0)\n",
    "    logFC = np.log2((means_in + 1e-6) / (means_out + 1e-6))\n",
    "    t_stat, p_val = stats.ttest_ind(\n",
    "        expr.loc[in_group],\n",
    "        expr.loc[out_group],\n",
    "        axis=0,\n",
    "        equal_var=False,\n",
    "        nan_policy=\"omit\"\n",
    "    )\n",
    "    de_df = pd.DataFrame({\n",
    "        \"gene\": expr.columns,\n",
    "        \"logFC\": logFC,\n",
    "        \"t\": t_stat,\n",
    "        \"pval\": p_val\n",
    "    }).sort_values(\"logFC\", ascending=False)\n",
    "\n",
    "    de_results[cl] = de_df\n",
    "\n",
    "    de_df[[\"gene\", \"logFC\"]].to_csv(\n",
    "        f\"DE_lists/{cl}_ranked_genes.rnk\",\n",
    "        sep=\"\\t\", index=False, header=False\n",
    "    )\n",
    "\n",
    "    print(f\"{cl}: saved {len(de_df)} genes to DE_lists/{cl}_ranked_genes.rnk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a6a8cb-3b15-46ec-bc25-f0d466a16f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnk_dir = \"DE_lists\"\n",
    "rnk_files = [f for f in os.listdir(rnk_dir) if f.endswith(\".rnk\")]\n",
    "gene_sets = \"MSigDB_Hallmark_2020\"\n",
    "all_results = []\n",
    "\n",
    "for file in sorted(rnk_files):\n",
    "    cluster_id = file.split(\"_\")[0]   \n",
    "    print(f\"Running GSEA for {cluster_id} ...\")\n",
    "\n",
    "    pre_res = gp.prerank(\n",
    "        rnk=os.path.join(rnk_dir, file),\n",
    "        gene_sets=gene_sets,\n",
    "        processes=4,            # number of CPU threads\n",
    "        permutation_num=1000,    \n",
    "        outdir=None,           \n",
    "        seed=42,\n",
    "        min_size=15,\n",
    "        max_size=500,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    df = pre_res.res2d.copy()\n",
    "    df[\"Cluster\"] = cluster_id\n",
    "    all_results.append(df)\n",
    "\n",
    "gsea_results = pd.concat(all_results)\n",
    "print(f\"\\nCombined GSEA results shape: {gsea_results.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0b3e4c-d9a0-48c2-a79e-41e844c2a6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Inspect what came back from gseapy\n",
    "print(\"GSEA results columns:\", gsea_results.columns.tolist())\n",
    "print(gsea_results.head(2))\n",
    "\n",
    "# 2) Standardize names\n",
    "df = gsea_results.copy().reset_index()\n",
    "df.columns = [str(c).strip().lower() for c in df.columns]\n",
    "\n",
    "# 3) Fix columns and ensure column names are correct\n",
    "if 'term' not in df.columns:\n",
    "    if 'name' in df.columns:\n",
    "        df = df.rename(columns={'name': 'term'})\n",
    "    elif 'geneset' in df.columns:\n",
    "        df = df.rename(columns={'geneset': 'term'})\n",
    "    elif \"index\" in df.columns:\n",
    "        df = df.rename(columns={'index': 'term'})\n",
    "    else:\n",
    "        raise KeyError(f\"Could not find pathway column; available: {df.columns.tolist()}\")\n",
    "\n",
    "#Fix any incorrect or strange naming conventions\n",
    "if 'nes' not in df.columns:\n",
    "    alt = [c for c in df.columns if 'nes' in c or 'normalized enrichment' in c]\n",
    "    if not alt:\n",
    "        raise KeyError(f\"Could not find NES column; available: {df.columns.tolist()}\")\n",
    "    df = df.rename(columns={alt[0]: 'nes'})\n",
    "    \n",
    "if 'cluster' not in df.columns and 'Cluster' in gsea_results.columns:\n",
    "    df = df.rename(columns={'Cluster': \"cluster\"})\n",
    "\n",
    "# 4) create the heatmap\n",
    "heatmap_df = df.pivot_table(index='term', columns='cluster', values='nes').fillna(0)\n",
    "\n",
    "# order clusters C1-C9 and make pathway names nicer\n",
    "desired_cols = [f\"C{i}\" for i in range(1, 10)]\n",
    "present_cols = [c for c in desired_cols if c in heatmap_df.columns]\n",
    "heatmap_df = heatmap_df.reindex(columns=present_cols)\n",
    "heatmap_df.index = (heatmap_df.index\n",
    "                    .str.replace('HALLMARK_', '', regex=False)\n",
    "                    .str.replace('_', ' ')\n",
    "                    .str.title())\n",
    "\n",
    "print('Heatmap matrix shape:', heatmap_df.shape)\n",
    "heatmap_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0507084a-259c-4171-a997-6546b83877ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 12))\n",
    "sns.heatmap(\n",
    "    heatmap_df,\n",
    "    cmap=\"RdBu_r\",\n",
    "    center=0,\n",
    "    linewidths=0.3,\n",
    "    linecolor='white',\n",
    "    cbar_kws={'label': 'NES'}\n",
    ")\n",
    "plt.title(\"Hallmark Pathway Enrichment per Cluster (NES)\", fontsize=14)\n",
    "plt.xlabel(\"Cluster\"); plt.ylabel(\"Hallmark Pathway\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"final_figures/GSEA_ranks/Figures/Pathway_enrichment_heatmap.png\", dpi=600, bbox_inches=\"tight\")\n",
    "fig.savefig(\"final_figures/GSEA_ranks/Figures/Pathway_enrichment_heatmap.pdf\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d43b6-afa2-4eea-b644-eea681dc2ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hallmark_sets))\n",
    "list(hallmark_sets.keys())[:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b504ad7e-f1a6-4a80-9b41-634dcb809ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    \"DNA Repair\",\n",
    "    \"Myc Targets V2\",\n",
    "    \"Reactive Oxygen Species Pathway\",\n",
    "    \"Unfolded Protein Response\",\n",
    "    \"Cholesterol Homeostasis\",\n",
    "]\n",
    "[x for x in hallmark_sets.keys() if \"dna\" in x.lower()]\n",
    "print(hallmark_sets[\"DNA Repair\"][:200])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b40f13-fea9-4255-bb46-b60c4949b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    \"DNA Repair\",\n",
    "    \"Myc Targets V2\",\n",
    "    \"Reactive Oxygen Species Pathway\",\n",
    "    \"Unfolded Protein Response\",\n",
    "    \"Cholesterol Homeostasis\",\n",
    "]\n",
    "\n",
    "# genes from pathways\n",
    "genes = sorted({\n",
    "    g for p in paths\n",
    "    for g in hallmark_sets.get(p, [])\n",
    "    if g in expr.columns\n",
    "})\n",
    "print(f\"{len(genes)} genes found across selected pathways.\")\n",
    "\n",
    "#z-score the exp vals\n",
    "X = expr[genes].copy()\n",
    "X_z = (X - X.mean()) / X.std(ddof=0)\n",
    "\n",
    "#add cluster info and sort by cluster\n",
    "X_z[\"cluster\"] = clustered_df[\"cluster_label\"]\n",
    "X_z = X_z.sort_values(\"cluster\")\n",
    "row_colors = X_z[\"cluster\"].map(palette)\n",
    "\n",
    "#plot one heatmap per pathway\n",
    "for p in paths:\n",
    "    print(f\"Plotting: {p}\")\n",
    "\n",
    "    g = [gg for gg in hallmark_sets.get(p, []) if gg in X_z.columns]\n",
    "    if not g:\n",
    "        print(f\"Skipping {p}: no overlapping genes.\")\n",
    "        continue\n",
    "    data = X_z[g].T.copy()\n",
    "    data = data.replace([np.inf, -np.inf], np.nan).dropna(how=\"any\")\n",
    "    if data.shape[0] < 2:\n",
    "        print(f\" Skipping {p}: not enough variable genes after cleaning.\")\n",
    "        continue\n",
    "    cg = sns.clustermap(\n",
    "        data,\n",
    "        cmap=\"vlag\",\n",
    "        center=0,\n",
    "        row_cluster=True,\n",
    "        col_cluster=False,\n",
    "        col_colors=row_colors,\n",
    "        xticklabels=False,\n",
    "        figsize=(10, 8),\n",
    "        cbar_kws={'label': 'Z-score'}\n",
    "    )\n",
    "    cg.ax_heatmap.set_title(p, fontsize=14, pad=10)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661b8f62-3c85-4203-9fab-2b7a5bcbaaea",
   "metadata": {},
   "source": [
    "### Differential Gene Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1977eb-6cba-4418-aa64-ef76e23b8277",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = expr.copy()\n",
    "clusters = clustered_df[\"cluster_label\"]\n",
    "unique_clusters = sorted(clusters.unique())\n",
    "N_TOP = 15  #top/cluster\n",
    "\n",
    "# one cluster differential expression vs. rest of clusters\n",
    "de_results = {}\n",
    "for cl in unique_clusters:\n",
    "    in_group = clusters[clusters == cl].index\n",
    "    out_group = clusters[clusters != cl].index\n",
    "\n",
    "    t_stat, p_val = stats.ttest_ind(expr.loc[in_group], expr.loc[out_group],\n",
    "                                    equal_var=False, nan_policy=\"omit\")\n",
    "    logFC = expr.loc[in_group].mean() - expr.loc[out_group].mean()\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"gene\": expr.columns,\n",
    "        \"logFC\": logFC,\n",
    "        \"t\": t_stat,\n",
    "        \"pval\": p_val\n",
    "    }).sort_values(\"logFC\", ascending=False)\n",
    "\n",
    "    de_results[cl] = df\n",
    "\n",
    "top_gene_list = []\n",
    "cluster_labels_for_rows = []\n",
    "for cl in unique_clusters:\n",
    "    genes = de_results[cl].head(N_TOP)[\"gene\"].tolist()\n",
    "    top_gene_list.extend(genes)\n",
    "    cluster_labels_for_rows.extend([cl] * len(genes))\n",
    "top_genes = []\n",
    "row_clusters = []\n",
    "for g, cl in zip(top_gene_list, cluster_labels_for_rows):\n",
    "    if g not in top_genes:\n",
    "        top_genes.append(g)\n",
    "        row_clusters.append(cl)\n",
    "cluster_means = expr.groupby(clusters).mean()[top_genes].T\n",
    "\n",
    "#z-score per gene \n",
    "mean_vals = cluster_means.mean(axis=1).to_numpy()[:, np.newaxis]\n",
    "std_vals = cluster_means.std(axis=1).to_numpy()[:, np.newaxis]\n",
    "cluster_means_z = (cluster_means - mean_vals) / std_vals\n",
    "cluster_means_z.index = pd.MultiIndex.from_arrays(\n",
    "    [cluster_means_z.index, row_clusters],\n",
    "    names=[\"Gene\", \"TopCluster\"]\n",
    ")\n",
    "\n",
    "# heatmap with gene labels & cluster boundaries\n",
    "sns.set(font_scale=0.6)\n",
    "plt.figure(figsize=(9, max(6, len(top_genes) / 4)))\n",
    "ax = sns.heatmap(\n",
    "    cluster_means_z,\n",
    "    cmap=\"vlag\",\n",
    "    center=0,\n",
    "    xticklabels=True,\n",
    "    yticklabels=[g for g in cluster_means_z.index.get_level_values(\"Gene\")],\n",
    "    cbar_kws={\"label\": \"Z-score\"}\n",
    ")\n",
    "\n",
    "# horizontal lines to separate clusters\n",
    "current = 0\n",
    "for cl in unique_clusters:\n",
    "    count = sum(np.array(row_clusters) == cl)\n",
    "    current += count\n",
    "    ax.hlines(current, *ax.get_xlim(), color=\"black\", lw=0.6)\n",
    "\n",
    "ax.set_title(\"Top Up-regulated Genes per Cluster\", fontsize=11, pad=10)\n",
    "ax.set_xlabel(\"Cluster\")\n",
    "ax.set_ylabel(\"Genes (Top 15 per Cluster)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"final_figures/DE/fig3A_topgenes_labeled.png\", dpi=600)\n",
    "plt.savefig(\"final_figures/DE/fig3A_topgenes_labeled.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87162c2-9493-4872-80f7-36e9026c2613",
   "metadata": {},
   "source": [
    "### Mutational Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f5551-9012-4d3a-8a74-a73c4f3444d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "mapping = pd.read_csv(\"gdc_mapping.tsv\", sep=\"\\t\")\n",
    "\n",
    "raw_folder = \"extracted/somatic_mutations\"\n",
    "renamed_folder = \"stripped/maf\"\n",
    "os.makedirs(renamed_folder, exist_ok=True)\n",
    "\n",
    "for _, row in mapping.iterrows():\n",
    "    file_id = row[\"File_ID\"]\n",
    "    file_name = row[\"File_Name\"]\n",
    "    case_id = row[\"Case_ID\"]\n",
    "\n",
    "    # Standardize Case_ID format using first 12 characters (as done previously). \n",
    "    case_id = case_id[:12]  \n",
    "\n",
    "    # copy .maf file\n",
    "    maf_path = None\n",
    "    for name in [file_id + \".maf\", file_name]:\n",
    "        path = os.path.join(raw_folder, name)\n",
    "        if os.path.exists(path):\n",
    "            maf_path = path\n",
    "            break\n",
    "\n",
    "    if maf_path:\n",
    "        new_name = f\"{case_id}.maf\"\n",
    "        shutil.copy(maf_path, os.path.join(renamed_folder, new_name))\n",
    "    else:\n",
    "        print(f\"File not found for {case_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5865fd-4632-482d-90eb-4dab4f2dc973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SigProfilerMatrixGenerator import SigProfilerMatrixGenerator as matGen\n",
    "from SigProfilerExtractor import sigpro as sig\n",
    "\n",
    "matGen.SigProfilerMatrixGeneratorFunc(\n",
    "    project=\"LU_fast\",\n",
    "    reference_genome=\"GRCh38\",\n",
    "    input_type=\"stripped/maf\",\n",
    "    exome=True\n",
    ")\n",
    "\n",
    "sig.sigProfilerExtractor(\n",
    "    input_type=\"matrix\",\n",
    "    input_data=\"LU_fast.SBS96.exome\",\n",
    "    output=\"extraction_output\",\n",
    "    reference_genome=\"GRCh38\",\n",
    "    minimum_signatures=2,\n",
    "    maximum_signatures=6,\n",
    "    nmf_replicates=30,\n",
    "    cpu=2,\n",
    "    resample=True,\n",
    "    make_decomposition_plots=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baad447e-c8da-4874-82ac-3ac4f5b1f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean COSMIC SBS signature exposures per cluster\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "expo_path = \"extraction_output/SBS96/All_Solutions/SBS96_6_Signatures/Activities/SBS96_S6_NMF_Activities.txt\"\n",
    "cluster_path = \"final_cluster_assignments.csv\"\n",
    "exp = pd.read_csv(expo_path, sep=\"\\t\")\n",
    "clusters = pd.read_csv(cluster_path)\n",
    "\n",
    "#fix namings \n",
    "clusters.columns = [c.lower() for c in clusters.columns]\n",
    "sample_col = next((c for c in clusters.columns if \"sample\" in c), clusters.columns[0])\n",
    "cluster_col = next((c for c in clusters.columns if \"cluster\" in c or \"label\" in c), clusters.columns[1])\n",
    "clusters = clusters.rename(columns={sample_col:\"sample_id\", cluster_col:\"cluster\"})\n",
    "exp = exp.rename(columns={exp.columns[0]:\"sample_id\"})\n",
    "\n",
    "# merge & compute cluster means\n",
    "merged = exp.merge(clusters, on=\"sample_id\", how=\"left\")\n",
    "sig_cols = [c for c in exp.columns if c != \"sample_id\"]\n",
    "cluster_mean = merged.groupby(\"cluster\")[sig_cols].mean().fillna(0)\n",
    "ordered = [f\"C{i}\" for i in range(1,10)]\n",
    "cluster_mean = cluster_mean.reindex([c for c in ordered if c in cluster_mean.index])\n",
    "\n",
    "colors = plt.cm.tab10(np.linspace(0,1,len(sig_cols)))\n",
    "fig, ax = plt.subplots(figsize=(1.5*len(cluster_mean),5))\n",
    "x = np.arange(len(cluster_mean))\n",
    "bar_width = 0.12\n",
    "for i, sig in enumerate(sig_cols):\n",
    "    ax.bar(x + i*bar_width - bar_width*len(sig_cols)/2,\n",
    "           cluster_mean[sig], width=bar_width, label=sig, color=colors[i])\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(cluster_mean.index)\n",
    "ax.set_ylabel(\"Mean signature exposure\")\n",
    "ax.set_title(\"Mean COSMIC SBS exposures per cluster\", pad=10)\n",
    "ax.legend(ncol=3, fontsize=8, frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/Fig6F_SignatureExposure_perCluster.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: figures/Fig6F_SignatureExposure_perCluster.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531868d2-1c4f-4d5c-9936-411a1f6463e9",
   "metadata": {},
   "source": [
    "### Mutation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86902c-2256-4ef1-89a2-592bb51b3b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "MERGED_PATH = \"merged_expression_mutation.csv\"\n",
    "CLUSTERS_CSV = \"final_cluster_assignments.csv\"\n",
    "EXOME_MB = 38.0\n",
    "TOP_N_MUT_GENES = 20\n",
    "\n",
    "immune_gene_map = {\n",
    "    \"PD1\": \"PDCD1\",\n",
    "    \"PDL1\": \"CD274\",\n",
    "    \"PD-L1\": \"CD274\",\n",
    "    \"PDL2\": \"PDCD1LG2\",\n",
    "    \"PD-L2\": \"PDCD1LG2\"\n",
    "}\n",
    "immune_targets = list(dict.fromkeys(immune_gene_map.values()))\n",
    "base_colors = [\"#1f77b4\",\"#ff7f0e\",\"#2ca02c\",\"#d62728\",\"#9467bd\",\n",
    "               \"#8c564b\",\"#e377c2\",\"#7f7f7f\",\"#17becf\"]\n",
    "os.makedirs(\"figures\", exist_ok=True)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "X = pd.read_csv(MERGED_PATH)\n",
    "if X.columns[0].lower() in {\"sample\",\"sample_id\",\"tumor_sample_barcode\",\"barcode\",\"case_id\",\"unnamed: 0\"}:\n",
    "    X = X.rename(columns={X.columns[0]: \"sample_id\"}).set_index(\"sample_id\")\n",
    "else:\n",
    "    X.index.name = \"sample_id\"\n",
    "\n",
    "n_cols = X.shape[1]\n",
    "half = n_cols // 2\n",
    "expr_df = X.iloc[:, :half].copy()\n",
    "mut_df  = X.iloc[:, half:].copy()\n",
    "expr_genes = expr_df.columns.tolist()\n",
    "mut_genes  = mut_df.columns.tolist()\n",
    "\n",
    "clusters = pd.read_csv(CLUSTERS_CSV)\n",
    "clusters.columns = [c.lower() for c in clusters.columns]\n",
    "sample_col = next((c for c in [\"sample_id\",\"sample\",\"tumor_sample_barcode\",\"barcode\",\"case_id\"] if c in clusters.columns), clusters.columns[0])\n",
    "cluster_col = next((c for c in [\"cluster_label\",\"cluster\",\"label\",\"group\",\"subtype\"] if c in clusters.columns), None)\n",
    "if cluster_col is None:\n",
    "    raise ValueError(\"No cluster column found.\")\n",
    "clusters = clusters.rename(columns={sample_col:\"sample_id\", cluster_col:\"cluster\"}).set_index(\"sample_id\")\n",
    "\n",
    "expr_df = expr_df.loc[expr_df.index.intersection(clusters.index)]\n",
    "mut_df  = mut_df.loc[mut_df.index.intersection(clusters.index)]\n",
    "clusters = clusters.loc[expr_df.index]\n",
    "ordered_clusters = sorted(clusters[\"cluster\"].unique().tolist())\n",
    "cluster_to_color = {cl: base_colors[i % len(base_colors)] for i, cl in enumerate(ordered_clusters)}\n",
    "\n",
    "# TMB \n",
    "mut_counts = mut_df.sum(axis=1)\n",
    "tmb = (mut_counts/EXOME_MB).rename(\"TMB_perMb\").to_frame().join(clusters)\n",
    "fig, ax = plt.subplots(figsize=(max(6,1.2*len(ordered_clusters)), 4))\n",
    "data = [tmb[tmb[\"cluster\"]==cl][\"TMB_perMb\"].values for cl in ordered_clusters]\n",
    "bp = ax.boxplot(data, labels=ordered_clusters, patch_artist=True)\n",
    "for i, patch in enumerate(bp[\"boxes\"]):\n",
    "    patch.set_facecolor(base_colors[i % len(base_colors)])\n",
    "for i, cl in enumerate(ordered_clusters, start=1):\n",
    "    y = data[i-1]\n",
    "    ax.plot(np.random.normal(i, 0.06, size=len(y)), y, \"o\", alpha=0.4, markersize=3, color=\"black\")\n",
    "ax.set_ylabel(\"TMB (mutations/Mb)\")\n",
    "ax.set_title(\"Tumor Mutational Burden per Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/Fig_TMB_PerCluster.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "tmb.to_csv(\"results/tmb_by_sample.tsv\", sep=\"\\t\")\n",
    "\n",
    "# oncoplot (top mutated genes)\n",
    "gene_freq = mut_df.sum(axis=0).sort_values(ascending=False).head(TOP_N_MUT_GENES)\n",
    "top_genes = gene_freq.index.tolist()\n",
    "M = mut_df[top_genes].loc[clusters.sort_values(\"cluster\").index]\n",
    "fig, ax = plt.subplots(figsize=(max(6, 0.4*len(top_genes)), max(6, 0.06*len(M))))\n",
    "im = ax.imshow(M.values, aspect=\"auto\", cmap=ListedColormap([\"#ffffff\",\"#000000\"]))\n",
    "ax.set_xticks(np.arange(len(top_genes)))\n",
    "ax.set_xticklabels(top_genes, rotation=90, fontsize=8)\n",
    "ax.set_yticks([])\n",
    "ax.set_title(\"Oncoplot-style Heatmap (Top Mutated Genes)\", pad=10)\n",
    "for i, s in enumerate(M.index):\n",
    "    ax.add_patch(Rectangle((-0.6,i-0.5),0.3,1.0,\n",
    "                  color=cluster_to_color.get(clusters.loc[s,\"cluster\"],\"#bbbbbb\"), lw=0))\n",
    "patches = [mpatches.Patch(color=cluster_to_color[cl], label=cl) for cl in ordered_clusters]\n",
    "ax.legend(handles=patches, title=\"Cluster\", bbox_to_anchor=(1.02,1), loc=\"upper left\", frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/Fig_Oncoplot_TopMutatedGenes.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# Stacked Bar Chart\n",
    "prev = []\n",
    "for cl in ordered_clusters:\n",
    "    idx = clusters.index[clusters[\"cluster\"]==cl]\n",
    "    prev.append((mut_df.loc[idx, top_genes].sum()/len(idx)).rename(cl))\n",
    "prev_df = pd.concat(prev, axis=1).T\n",
    "fig, ax = plt.subplots(figsize=(max(8,0.5*len(prev_df.columns)),5))\n",
    "bottom = np.zeros(len(prev_df))\n",
    "for g in prev_df.columns:\n",
    "    vals = prev_df[g].values\n",
    "    ax.bar(np.arange(len(prev_df)), vals, bottom=bottom, label=g)\n",
    "    bottom += vals\n",
    "ax.set_xticks(np.arange(len(prev_df)))\n",
    "ax.set_xticklabels(prev_df.index)\n",
    "ax.set_ylabel(\"Fraction mutated\")\n",
    "ax.set_title(\"Prevalence of Top Mutated Genes per Cluster\")\n",
    "ax.legend(ncol=min(4,len(prev_df.columns)), fontsize=8, frameon=False, bbox_to_anchor=(1.02,1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/Fig_Stacked_Prevalence_TopMutated_byCluster.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "prev_df.to_csv(\"results/prevalence_top_mutated_per_cluster.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7a74c9-671f-4975-a995-998316b383b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 most frequently mutated genes/cluster\n",
    "df = pd.read_csv(MERGED_PATH)\n",
    "if df.columns[0].lower() in {\"sample\",\"sample_id\",\"tumor_sample_barcode\",\"barcode\",\"case_id\",\"unnamed: 0\"}:\n",
    "    df = df.rename(columns={df.columns[0]: \"sample_id\"}).set_index(\"sample_id\")\n",
    "else:\n",
    "    df.index.name = \"sample_id\"\n",
    "\n",
    "# mutation frequency/cluster\n",
    "top_per_cluster = {}\n",
    "for cl in sorted(clusters[\"cluster\"].unique()):\n",
    "    idx = clusters.index[clusters[\"cluster\"] == cl]\n",
    "    sub = mut_df.loc[idx]\n",
    "    freq = sub.sum(axis=0) / len(sub)\n",
    "    top10 = freq.sort_values(ascending=False).head(10)\n",
    "    top_per_cluster[cl] = top10\n",
    "\n",
    "out_rows = []\n",
    "for cl, s in top_per_cluster.items():\n",
    "    for gene, val in s.items():\n",
    "        out_rows.append({\"cluster\": cl, \"gene\": gene, \"mutation_fraction\": val})\n",
    "out_df = pd.DataFrame(out_rows)\n",
    "\n",
    "out_df.to_csv(\"results/top10_mutated_genes_per_cluster.tsv\", sep=\"\\t\", index=False)\n",
    "print(\"Saved: results/top10_mutated_genes_per_cluster.tsv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad2ac61-d2b6-4213-ba22-8ca6c0f77f10",
   "metadata": {},
   "source": [
    "### Immune Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed29617-d713-4455-9c6d-f17672969dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "immune_targets = list(dict.fromkeys(immune_gene_map.values()))\n",
    "expr_cols = list(expr_df.columns)\n",
    "expr_present = [g for g in immune_targets if g in expr_cols]\n",
    "if len(expr_present) < len(immune_targets):\n",
    "    lower_map = {c.lower():c for c in expr_cols}\n",
    "    for g in immune_targets:\n",
    "        if g.lower() in lower_map and lower_map[g.lower()] not in expr_present:\n",
    "            expr_present.append(lower_map[g.lower()])\n",
    "#Boxplots\n",
    "for g in expr_present:\n",
    "    fig, ax = plt.subplots(figsize=(max(6,1.2*len(ordered_clusters)),4))\n",
    "    data = [expr_df.loc[clusters[\"cluster\"]==cl, g].values for cl in ordered_clusters]\n",
    "    bp = ax.boxplot(data, labels=ordered_clusters, patch_artist=True)\n",
    "    for i,patch in enumerate(bp[\"boxes\"]):\n",
    "        patch.set_facecolor(base_colors[i % len(base_colors)])\n",
    "    for i,cl in enumerate(ordered_clusters, start=1):\n",
    "        y = data[i-1]\n",
    "        ax.plot(np.random.normal(i,0.06,len(y)), y, \"o\", alpha=0.35, markersize=3, color=\"black\")\n",
    "    ax.set_title(f\"{g} expression per cluster (log₂(TPM+1))\")\n",
    "    ax.set_ylabel(\"Expression\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"figures/Fig_Box_{g}_perCluster.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4700f8c5-ac5b-4c8f-89b1-93e2ac2934c8",
   "metadata": {},
   "source": [
    "### Clinical Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c67ec2c-a2e6-4cb4-928a-521d084d156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.0)\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5177a6-1420-4185-a167-e25e7e6a152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = pd.read_csv(\"final_cluster_assignments.csv\", header=None)\n",
    "clusters.columns = [\"Case_ID\", \"cluster_label\"]\n",
    "clusters[\"Case_ID\"] = clusters[\"Case_ID\"].str[:12].str.upper()\n",
    "\n",
    "#Clinical Data\n",
    "clinical = pd.read_csv(\"clinical.tsv\", sep=\"\\t\", low_memory=False)\n",
    "clinical[\"cases.submitter_id\"] = clinical[\"cases.submitter_id\"].astype(str).str[:12].str.upper()\n",
    "merged = clinical.merge(clusters, how=\"inner\",\n",
    "                        left_on=\"cases.submitter_id\", right_on=\"Case_ID\")\n",
    "print(\"Merge complete:\", merged.shape)\n",
    "\n",
    "#cleanup steps \n",
    "clinical_unique = clinical.drop_duplicates(subset=[\"cases.submitter_id\"], keep=\"first\")\n",
    "merged = clinical_unique.merge(clusters, how=\"inner\",\n",
    "                               left_on=\"cases.submitter_id\", right_on=\"Case_ID\")\n",
    "merged.to_csv(\"merged_clinical_clusters_dedup.csv\", index=False)\n",
    "\n",
    "# ER-ACGR-TTP was missing, no clinical data on it. \n",
    "if \"ER-ACGR-TTP\" not in merged[\"Case_ID\"].values:\n",
    "    cl = clusters.loc[clusters[\"Case_ID\"].str[:12] == \"ER-ACGR-TTP\", \"cluster_label\"].iloc[0]\n",
    "    merged = pd.concat([merged, pd.DataFrame([{\n",
    "        \"Case_ID\": \"ER-ACGR-TTP\", \"cluster_label\": cl,\n",
    "        \"cases.submitter_id\": \"ER-ACGR-TTP\",\n",
    "        \"demographic.gender\": \"Unknown\",\n",
    "        \"demographic.race\": \"Unknown\",\n",
    "        \"demographic.age_at_index\": None,\n",
    "        \"diagnoses.ajcc_pathologic_stage\": \"Unknown\",\n",
    "        \"cases.disease_type\": \"Unknown\"\n",
    "    }])], ignore_index=True)\n",
    "\n",
    "merged.to_csv(\"merged_clinical_clusters_final.csv\", index=False)\n",
    "print(\"Saved merged_clinical_clusters_final.csv (n=\", len(merged), \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c623e3fb-b514-4c3b-bbdd-8a05940363b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_csv(\"merged_clinical_clusters_final.csv\")\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# gender\n",
    "g = merged[\"demographic.gender\"].fillna(\"Unknown\").value_counts().reset_index()\n",
    "g.columns = [\"Gender\",\"Count\"]\n",
    "sns.barplot(data=g, x=\"Gender\", y=\"Count\",\n",
    "            palette=[\"#4C72B0\",\"#F781BF\",\"#BDBDBD\"], ax=axes[0])\n",
    "axes[0].set_title(\"Gender\")\n",
    "\n",
    "# race\n",
    "r = merged[\"demographic.race\"].fillna(\"Unknown\").value_counts().reset_index()\n",
    "r.columns = [\"Race\",\"Count\"]\n",
    "sns.barplot(data=r, x=\"Race\", y=\"Count\", palette=\"Blues\", ax=axes[1])\n",
    "axes[1].set_title(\"Race / Ethnicity\"); axes[1].tick_params(axis=\"x\", rotation=30)\n",
    "\n",
    "# age\n",
    "merged[\"demographic.age_at_index\"] = pd.to_numeric(\n",
    "    merged[\"demographic.age_at_index\"], errors=\"coerce\")\n",
    "sns.histplot(data=merged, x=\"demographic.age_at_index\", bins=15,\n",
    "             color=\"#4C72B0\", kde=True, ax=axes[2])\n",
    "axes[2].set_title(\"Age at Diagnosis\")\n",
    "\n",
    "# histology\n",
    "h = merged[\"cases.disease_type\"].fillna(\"Unknown\").value_counts().reset_index()\n",
    "h.columns = [\"Histology\",\"Count\"]\n",
    "sns.barplot(data=h, x=\"Histology\", y=\"Count\",\n",
    "            palette=[\"#9ECAE1\",\"#FCAE91\",\"#BDBDBD\"], ax=axes[3])\n",
    "axes[3].set_title(\"Histopathologic Subtype\"); axes[3].tick_params(axis=\"x\", rotation=25)\n",
    "\n",
    "# stage\n",
    "s = merged[\"diagnoses.ajcc_pathologic_stage\"].fillna(\"Unknown\").value_counts().reset_index()\n",
    "s.columns = [\"Stage\",\"Count\"]\n",
    "sns.barplot(data=s, x=\"Stage\", y=\"Count\", palette=\"Greens\", ax=axes[4])\n",
    "axes[4].set_title(\"AJCC Pathologic Stage\"); axes[4].tick_params(axis=\"x\", rotation=30)\n",
    "\n",
    "# blank for smoking/survival. IDK which one should go there, will manually paste. \n",
    "axes[5].axis(\"off\")\n",
    "axes[5].text(0.5,0.5,\"Panel reserved for\\nsmoking or survival summary\",\n",
    "             ha=\"center\", va=\"center\", color=\"gray\")\n",
    "\n",
    "plt.suptitle(f\"Figure 1 – Cohort Demographics (n={len(merged)})\", fontsize=14, y=1.02)\n",
    "plt.tight_layout(); plt.savefig(\"Fig1_Cohort_Demographics.png\", dpi=600, bbox_inches=\"tight\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f094b4-5f60-46f9-b9ce-94a331507c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kaplan-Meier\n",
    "!pip install lifelines --quiet\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import multivariate_logrank_test\n",
    "\n",
    "merged = pd.read_csv(\"merged_clinical_clusters_final.csv\")\n",
    "\n",
    "merged[\"status\"] = merged[\"demographic.vital_status\"].map({\"Alive\":0, \"Dead\":1})\n",
    "merged[\"time\"] = merged[\"demographic.days_to_death\"].fillna(\n",
    "    merged[\"diagnoses.days_to_last_follow_up\"])\n",
    "merged[\"time\"] = pd.to_numeric(merged[\"time\"], errors=\"coerce\")\n",
    "\n",
    "kmf = KaplanMeierFitter()\n",
    "palette = sns.color_palette(\"husl\", n_colors=merged[\"cluster_label\"].nunique())\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "for i, (cl, subdf) in enumerate(merged.groupby(\"cluster_label\")):\n",
    "    subdf = subdf.dropna(subset=[\"time\",\"status\"])\n",
    "    kmf.fit(subdf[\"time\"], event_observed=subdf[\"status\"], label=cl)\n",
    "    kmf.plot_survival_function(ci_show=False, color=palette[i])\n",
    "plt.xlabel(\"Days\"); plt.ylabel(\"Survival probability\")\n",
    "plt.title(\"Kaplan–Meier Survival by Cluster\")\n",
    "plt.tight_layout(); plt.savefig(\"Fig_Survival_KM.png\", dpi=600); plt.show()\n",
    "\n",
    "res = multivariate_logrank_test(\n",
    "    merged[\"time\"], merged[\"cluster_label\"], event_observed=merged[\"status\"])\n",
    "print(\"Global log-rank p-value:\", res.p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573dfd0c-7271-497a-9852-9e0dd317504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoking\n",
    "exposure = pd.read_csv(\"exposure.tsv\", sep=\"\\t\")\n",
    "exposure[\"cases.submitter_id\"] = exposure[\"cases.submitter_id\"].astype(str).str[:12].str.upper()\n",
    "\n",
    "tobacco = exposure[\n",
    "    exposure[\"exposures.tobacco_smoking_status\"].notna() |\n",
    "    exposure[\"exposures.smoking_frequency\"].notna() |\n",
    "    exposure[\"exposures.pack_years_smoked\"].notna() |\n",
    "    exposure[\"exposures.type_of_tobacco_used\"].notna()\n",
    "].copy()\n",
    "\n",
    "merged = pd.read_csv(\"merged_clinical_clusters_final.csv\")\n",
    "merged[\"Case_ID\"] = merged[\"Case_ID\"].astype(str).str[:12].str.upper()\n",
    "merged = merged.merge(\n",
    "    tobacco[[\"cases.submitter_id\",\"exposures.tobacco_smoking_status\",\n",
    "             \"exposures.pack_years_smoked\",\"exposures.smoking_frequency\",\n",
    "             \"exposures.years_smoked\",\"exposures.type_of_tobacco_used\"]],\n",
    "    left_on=\"Case_ID\", right_on=\"cases.submitter_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "def simplify_smoking(x):\n",
    "    if pd.isna(x): return \"Unknown\"\n",
    "    x = x.lower()\n",
    "    if \"lifelong\" in x or \"non\" in x or \"never\" in x: return \"Never\"\n",
    "    elif \"current\" in x and \"reformed\" not in x: return \"Current\"\n",
    "    elif \"reformed\" in x or \"former\" in x: return \"Former\"\n",
    "    else: return \"Other\"\n",
    "\n",
    "merged[\"smoking_status_clean\"] = merged[\"exposures.tobacco_smoking_status\"].apply(simplify_smoking)\n",
    "\n",
    "summary = (\n",
    "    merged.groupby([\"cluster_label\",\"smoking_status_clean\"]).size().reset_index(name=\"count\")\n",
    ")\n",
    "summary[\"percent\"] = summary.groupby(\"cluster_label\")[\"count\"].transform(lambda x: x/x.sum()*100)\n",
    "\n",
    "pivot = summary.pivot(index=\"cluster_label\", columns=\"smoking_status_clean\", values=\"percent\").fillna(0)\n",
    "order = [c for c in [\"Never\",\"Former\",\"Current\",\"Unknown\"] if c in pivot.columns]\n",
    "pivot = pivot[order]\n",
    "\n",
    "pivot.plot(kind=\"bar\", stacked=True, figsize=(8,4),\n",
    "           color=[\"#91bfdb\",\"#fc8d59\",\"#d73027\",\"#d9d9d9\"])\n",
    "plt.ylabel(\"% of cases\"); plt.xlabel(\"Cluster\")\n",
    "plt.title(\"Smoking status per cluster\")\n",
    "plt.legend(title=\"Smoking status\", bbox_to_anchor=(1.02,1), loc=\"upper left\")\n",
    "plt.tight_layout(); plt.savefig(\"Fig_Smoking_Clusters.png\", dpi=600); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dad7a9-fae5-4de3-be94-586611938e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixed TMB Figure\n",
    "M = pd.read_csv(\"merged_exp_mut.csv\", index_col=0)\n",
    "N_GENES = 19938\n",
    "mut_cols = M.columns[-N_GENES:]\n",
    "clusters = pd.read_csv(\"final_cluster_assignments.csv\", header=None, names=[\"Case_ID\",\"cluster_label\"])\n",
    "clusters[\"Case_ID\"] = clusters[\"Case_ID\"].str[:12].str.upper()\n",
    "M.index = M.index.str[:12].str.upper()\n",
    "M = M.merge(clusters, left_index=True, right_on=\"Case_ID\", how=\"inner\")\n",
    "\n",
    "freq_df = []\n",
    "for cl in sorted(M[\"cluster_label\"].unique()):\n",
    "    sub = M[M[\"cluster_label\"]==cl][mut_cols].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "    freq = sub.sum(axis=0)/len(sub)*100\n",
    "    freq_df.append(freq.rename(cl))\n",
    "freq_df = pd.DataFrame(freq_df).T\n",
    "\n",
    "top_genes = freq_df.mean(axis=1).sort_values(ascending=False).head(10).index\n",
    "plot_df = freq_df.loc[top_genes].T.reset_index().melt(\n",
    "    id_vars=\"index\", var_name=\"Gene\", value_name=\"Percent\"\n",
    ").rename(columns={\"index\":\"Cluster\"})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "palette = sns.color_palette(\"tab10\", n_colors=len(top_genes))\n",
    "bottom = pd.Series([0]*plot_df[\"Cluster\"].nunique(),\n",
    "                   index=sorted(plot_df[\"Cluster\"].unique()))\n",
    "for gene, color in zip(top_genes, palette):\n",
    "    vals = plot_df[plot_df[\"Gene\"]==gene].set_index(\"Cluster\")[\"Percent\"].reindex(bottom.index, fill_value=0)\n",
    "    ax.bar(bottom.index, vals, bottom=bottom, label=gene, color=color)\n",
    "    bottom += vals\n",
    "ax.set_ylabel(\"Percent of cases mutated (%)\")\n",
    "ax.set_xlabel(\"Cluster\")\n",
    "ax.set_title(\"Top mutated genes per cluster\")\n",
    "ax.legend(title=\"Gene\", bbox_to_anchor=(1.05,1), loc=\"upper left\", frameon=False, fontsize=9)\n",
    "sns.despine(ax=ax)\n",
    "plt.tight_layout(); plt.savefig(\"Fig_Mutation_StackedBar.png\", dpi=600); plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
